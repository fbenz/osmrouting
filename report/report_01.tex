\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}  % import graphics
\usepackage{listings}  % support source code listing
\usepackage{amsmath}  % math stuff
\usepackage{amssymb} % 
\usepackage{a4wide} % wide pages
\usepackage{fancyhdr} % nice headers
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{petri}

\lstset{basicstyle=\footnotesize,language=Python,numbers=left, numberstyle=\tiny, stepnumber=5,firstnumber=0, numbersep=5pt} % set up listings
\pagestyle{fancy}             % header

\usepackage[none]{hyphenat}
\sloppy

% change enums style: first level (a), (b), (c)           
\renewcommand{\labelenumi}{\arabic{enumi}.}
\renewcommand{\labelenumii}{\alph{enumii})}

%term/semester
\newcommand{\term}{
	Summer 2012 -- Saarland University
} 

%lecture name
\newcommand{\lecture}{
	Algorithm Engineering
}           

%assignment iteration
\newcommand{\assignment}{
	Team FortyTwo Report
}

%set up names, matricle number, and email
\newcommand{\authors}{
  Florian Benz, Steven Schäfer, Bernhard Schommer
}

% use to start a new exercise
\newcommand{\exercise}[1]
{
  \stepcounter{subsection}
  \subsection*{Exercise \thesubsection: #1}

}

\begin{document}
\title{
  \vspace{-3cm}
  \large
  \lecture \\
  \small \term \\
  \huge \assignment
}
\author{\small \authors}

\setlength \headheight{25pt}
\fancyhead[R]{\begin{tabular}{r}\lecture \\ \assignment \end{tabular}}
\fancyhead[L]{\authors}

\maketitle

\section{Overview}
First, we preprocess the OSM data to extract a street graph consisting of intersections in the original graph.
For each travel mode we currently emit a separate graph containing only those vertices and edges relevant for the travel mode.
Our graph format consits of a compressed sparse row representation of the graph.
Each vertex and edge can be uniquely identified by its offset.
We use this to store additional attributes like distance, steps, or positions in separate files.

During the startup of the server, all files are mapped into the server's address space.
As a result our startup overhead is negligible and we do not have to load data from disk afterwards.
This has been a boon for testing.

When a query arrives, we find for each waypoint the nearest node in the OSM data.
This might not correspond to a vertex in our street graph;
in this case the node lies on an edge and we compute all reachable endpoints of this edge.
At this point, we run Dijkstra's algorithm on the street graph.
Finally, the resulting JSON object is created and returned.

The street graph is significantly smaller than the original OSM graph.
Furthermore, it is sparse; the average outdegree is around 2.4.
This means that Dijkstra's algorithm is efficient with a simple binary heap.

To find the nearest neighbor, we use a k-d tree with $k=2$ which is precomputed.
This results in very fast queries during runtime.
The construction algorithm is reminiscent of quicksort and can be parallelized efficiently.
On disk the k-d tree is stored as a permutation of vertex and step indices.

We use Go as our implementation language.
Go is a modern, concurrent and statically compiled programming language.
As the standard library comes with a HTTP server and JSON marschaling,
the initial implementation went very smoothly.

\section{Encountered Problems}
structure of OSM data (strange values...),
performance degradation due to too many memory allocations,
memory usage of the parser

\section{Additional Features}

Our server can perform concurrent non-blocking logging with accurate timing information.
In addition, the server can output profiling data for a request.
This has already been useful in troubleshooting performance problems.

Additionally, we have created a small JavaScript based frontend that 
gives us an easy way to test and visualize the results of our implementation.

\section{Future Work}

Even for a route request from Saarbrücken to Frankfurt Dijkstra's algorithm takes an inordinate amount of time (1 second).
Therefore, we are going to implement an algorithm based on transit node routing.
Furthermore, we have to ensure that the street graphs continue to fit into memory.
We are going to accomplish this by using succinct data structures;
Elias Fano encoding for vertex indices and delta compression for edges and positions.

The quality of the input data is also an issue.
Currently there are mutiple strongly connected components in the input data.
In the future we are going to partition the graph and throw away erroneous nodes.
Finding strongly connected components in large graphs is a difficult problem.
However, since we know that the graph contains a large SCC,
a simple randomized strategy can be used.

To improve the compression and locality, we intend to use a locality preserving ordering based on space filling curves
(e.g. Hilbert curves).  

metric

\begin{thebibliography}{9}

\bibitem{lamport94}
  Leslie Lamport,
  \emph{\LaTeX: A Document Preparation System}.
  Addison Wesley, Massachusetts,
  2nd Edition,
  1994.

\end{thebibliography}

\end{document}
